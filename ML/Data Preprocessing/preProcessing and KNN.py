# -*- coding: utf-8 -*-
"""ML1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s1pNeg35XA1mHq8EIRjN79bjqGVOrcGz
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from google.colab import drive

from sklearn.preprocessing  import StandardScaler
from imblearn.over_sampling import RandomOverSampler
drive.mount("/content/drive")

data_set = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Dataset.csv")

print(data_set)

#Extracting Independent Variable
x= data_set.iloc[:, :-1].values

print(x)

#Extracting Dependent variable
y= data_set.iloc[:, 3].values

print(y)

#handling missing data(Replacing missing data with the mean value)
from sklearn.impute import SimpleImputer
imputer= SimpleImputer(strategy='mean')

#Fitting imputer object to the independent varibles x.
imputerimputer= imputer.fit(x[:, 1:3])

#Replacing missing data with the calculated mean value
x[:, 1:3]= imputer.transform(x[:, 1:3])

print(x)

#Catgorical data
#for Country Variable
from sklearn.preprocessing import LabelEncoder
label_encoder_x= LabelEncoder()
x[:, 0]= label_encoder_x.fit_transform(x[:, 0])

print(x)

#for Country Variable
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
label_encoder_x= LabelEncoder()
x[:, 0]= label_encoder_x.fit_transform(x[:, 0])
#Encoding for dummy variables
ct = ColumnTransformer([("Country", OneHotEncoder(), [0])], remainder = 'passthrough')
x = ct.fit_transform(x)
#onehot_encoder= OneHotEncoder(categorical_features= [0])
#x= onehot_encoder.fit_transform(x).toarray()

print(x)

y = (y == 'Yes').astype(int)
print(y)

"""# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)

"""

# Splitting the dataset into training and test set.
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)

print(x_train)

print(x_test)

print(x)

print(y_test)

print(y_train)

print(y)

#Feature Scaling of datasets
from sklearn.preprocessing import StandardScaler
st_x= StandardScaler()
x_train= st_x.fit_transform(x_train)
x_test= st_x.transform(x_test)

print(x_train)



from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report

knn_model = KNeighborsClassifier(n_neighbors = 2)
knn_model.fit(x_train,y_train)

y_pred = knn_model.predict(x_test)

print(classification_report(y_test, y_pred))

